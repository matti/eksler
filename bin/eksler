#!/usr/bin/env bash
set -eumo pipefail

_shutdown() {
  trap '' TERM INT ERR
  echo ""
  echo "SHUTDOWN ($0)"

  trap '' TERM INT ERR

  kill 0
  wait

  echo "bye. $0"
  exit 0
}

trap _shutdown TERM INT ERR

_echoerr() {
  1>&2 echo "$@"
}

_output() {
  _echoerr " --[ $0 ]--[ $SECONDS ]-- $*"
}

_err() {
  _output "err: $*"
  exit 1
}

_forever() {
  while true; do
    _output "_forever: $*"
    eval "$*" && break
    sleep 1
  done
}

_never() {
  while true; do
    _output "_never: $*"
    eval "$*" || break
    sleep 1
  done
}

_forever_any() {
  while true; do
    value=$(eval "$*" || true)
    [ "$?" = "0" ] && [ "$value" != "" ] && break
    sleep 1
  done

  echo "$value"
}

_done() {
  echo ""
  _output "$* DONE in ${SECONDS}s"
}

_exit_unless_namespace_eksler() {
  while true; do
    kubectl_namespace_output=$(kubectl get namespace "eksler" --ignore-not-found) && break
    sleep 1
  done

  [ "$kubectl_namespace_output" = "" ] && exit
}

export AWS_PAGER=""
export EKSCTL_COMMON_OPTS="-C false"

eksctl_version_expected="0.96.0-rc.0"
eksctl_version_actual=$(eksctl "$EKSCTL_COMMON_OPTS" version)
if [ "$eksctl_version_actual" != "$eksctl_version_expected" ]; then
  _err "eksctl version is '$eksctl_version_actual' expected '$eksctl_version_expected'"
fi

ec2_instance_selector_version_expected="v2.3.0"
ec2_instance_selector_version_actual=$(ec2-instance-selector --version)
if [ "$ec2_instance_selector_version_expected" != "$ec2_instance_selector_version_actual" ]; then
  _err "ec2-instance-selector version is '$ec2_instance_selector_version_actual' expected '$ec2_instance_selector_version_expected'"
fi

handled=yes
subcommand=${1:-}
case "${subcommand}" in
  regions)
    while true; do
      if output=$(aws ec2 --region us-east-1 describe-regions --output text  --query='Regions[*].RegionName'); then
        break
      fi
      sleep 1
    done

    echo "$output" | sort | xargs
  ;;
  list)
    region=${2:-}
    if [ "$region" = "" ]; then
      for region in $($0 regions); do
        $0 list "$region"
      done

      exit
    fi

    while true; do
      if output=$(
        2>/dev/null eksctl "$EKSCTL_COMMON_OPTS" get cluster --region="$region" --output=json
      ); then
        break
      fi
    done

    [ "$output" = "[]" ] && exit 0

    echo "$output" | jq -re '.[] | .Region + " " + .Name'
  ;;
  ami)
    region=$2
    kubernetes_version=$3

    while true; do
      aws ec2 describe-images \
        --region "$region" \
        --filters "Name=name,Values=*amazon-eks-node-${kubernetes_version}-*" "Name=architecture,Values=x86_64" \
        --query "sort_by(Images, &CreationDate)[-1].ImageId" \
        --output text && break
      sleep 1
    done
  ;;
  *)
    handled=no
  ;;
esac
[ "$handled" = "yes" ] && exit 0

export REGION=$3
export CLUSTER_NAME=$4
export KUBECONFIG="${KUBECONFIG:-$HOME/.kube/aws-eks-${REGION}-${CLUSTER_NAME}}"

subsubcommand=$2

handled=yes
case "${subcommand}" in
  cluster)
    case "${subsubcommand}" in
      get)
        while true; do
          output=$(2>&1 eksctl get cluster --region="$REGION" "$CLUSTER_NAME" --output=json || true)

          case $output in
            *"StatusCode: 404"*)
              _err "cluster '$CLUSTER_NAME' not found in region '$REGION'"
              exit 1
            ;;
            *ACTIVE*)
              echo "$output" | tail -n +3
              break
            ;;
            *)
              _echoerr "$output"
            ;;
          esac

          sleep 1
        done
      ;;
      version)
        while true; do
          >/dev/null $0 cluster get "$REGION" "$CLUSTER_NAME" || exit 1

          if version=$(
            2>/dev/null eksctl "$EKSCTL_COMMON_OPTS" get cluster --region="$REGION" "$CLUSTER_NAME" --output=json | jq -r -e '.[].Version'
          ); then
            break
          fi
        done

        echo "$version"
      ;;
      delete)
        $0 managednodegroup delete-all "$REGION" "$CLUSTER_NAME"

        while true; do
          $0 cluster get "$REGION" "$CLUSTER_NAME" || break

          eksctl "$EKSCTL_COMMON_OPTS" delete cluster --region="$REGION" --name="$CLUSTER_NAME" --wait --force || true
        done

        for stack_name in eksctl-$CLUSTER_NAME-cluster eksctl-$CLUSTER_NAME-addon-vpc-cni; do
          while true; do
            while true; do
              if describe_stacks_output=$(aws --region="$REGION" cloudformation describe-stacks --output=json); then
                break
              fi
              sleep 1
            done

            echo "$describe_stacks_output" | jq -r -e --arg StackName "$stack_name" '.Stacks[] | select(.StackName==$StackName)' || break

            aws --region="$REGION" cloudformation delete-stack --stack-name="$stack_name" || true
          done
        done
      ;;
      ensure)
        $0 cluster get "$REGION" "$CLUSTER_NAME" && exit
        exec $0 cluster create "$REGION" "$CLUSTER_NAME" "${@:5}"
      ;;
      create)
        network=$5
        kubernetes_version=$6

        # TODO: https://github.com/weaveworks/eksctl/pull/5078
        echo """
apiVersion: eksctl.io/v1alpha5
kind: ClusterConfig

metadata:
  name: '${CLUSTER_NAME}'
  region: '${REGION}'
  version: '${kubernetes_version}'

addons:
  - name: vpc-cni
    version: latest     # NOTE: has to be present, otherwise some random version
  - name: coredns
    version: latest     # NOTE: has to be present, otherwise some random version
  - name: kube-proxy
    version: latest     # NOTE: has to be present, otherwise some random version
iam:
  withOIDC: true
""" >"/tmp/eksler.$REGION.$CLUSTER_NAME.cluster.yml"

        case "$network" in
          ipv6)
            echo """
kubernetesNetworkConfig:
  ipFamily: IPv6
""" >>"/tmp/eksler.$REGION.$CLUSTER_NAME.cluster.yml"
          ;;
          ipv4)
            :
          ;;
          *)
            _err "unknown network: $network"
          ;;
        esac

        cat "/tmp/eksler.$REGION.$CLUSTER_NAME.cluster.yml"

        while true; do
          $0 cluster get "$REGION" "$CLUSTER_NAME" && break

          if ! eksctl "$EKSCTL_COMMON_OPTS" create cluster -f "/tmp/eksler.$REGION.$CLUSTER_NAME.cluster.yml"; then
            $0 cluster delete "$REGION" "$CLUSTER_NAME"
          fi
        done

        _done "cluster create"
      ;;
      kubeconfig)
        while true; do
          >/dev/null $0 cluster get "$REGION" "$CLUSTER_NAME" || exit 1

          >/dev/null 2>&1 eksctl utils write-kubeconfig --region="$REGION" --cluster="$CLUSTER_NAME" --kubeconfig="$KUBECONFIG" && break
        done

        echo "$KUBECONFIG"
      ;;
      kubeconfig:contents)
        cat "$($0 cluster kubeconfig "$REGION" "$CLUSTER_NAME")"
      ;;
      delete-loadbalancers)
        while true; do
          kubectl get svc --all-namespaces -o=jsonpath='{.items[?(@.spec.type=="LoadBalancer")]}' | kubectl delete -f - && break
          sleep 1
        done
      ;;
      kubectl)
        exec kubectl "${@:5}"
      ;;
      helm)
        exec helm "${@:5}"
      ;;
      exec)
        exec "${@:5}"
      ;;
      *)
        handled=no
      ;;
    esac
  ;;
  managednodegroup)
    >/dev/null $0 cluster get "$REGION" "$CLUSTER_NAME" || _err "no such cluster '$CLUSTER_NAME' in region '$REGION'"

    handled=yes
    case "$subsubcommand" in
     list)
        while true; do
          if output=$(2>/dev/null eksctl "$EKSCTL_COMMON_OPTS" get nodegroups --region="$REGION" --cluster="$CLUSTER_NAME" --output=json); then
            break
          fi
          sleep 1
        done
        [ "$output" = "[]" ] && exit

        echo "$output" | jq -r '.[].Name' | sort
      ;;
      delete-all)
        for managednodegroup in $($0 managednodegroup list "$REGION" "$CLUSTER_NAME"); do
          (
            $0 managednodegroup delete "$REGION" "$CLUSTER_NAME" "$managednodegroup"
          ) 2>&1 | sed -le "s#^#$managednodegroup: #;" &
        done

        wait
      ;;
      *)
        handled=no
      ;;
    esac

    [ "$handled" = "yes" ] && exit

    name=$5
    case "$subsubcommand" in
      get)
        while true; do
          output=$(2>&1 eksctl "$EKSCTL_COMMON_OPTS" get nodegroup --region="$REGION" --cluster="$CLUSTER_NAME" --output=json "$name" || true)

          case $output in
            *"StatusCode: 404"*)
              exit 1
            ;;
            *"StatusCode: 400"*)
              # also when it does not exist
              exit 1
            ;;
            *ACTIVE*)
              break
            ;;
            *CREATING*)
              :
            ;;
            *)
              _echoerr "$output"
            ;;
          esac

          sleep 1
        done

        _exit_unless_namespace_eksler

        while true; do
          output=$(kubectl get configmap -n "eksler" "managednodegroup-$name" -o jsonpath='{.data.yaml}' || true)
          [ "$output" != "" ] && break
          sleep 1
        done

        printf "%s\n" "$output"
        exit
      ;;
      delete)
        while true; do
          >/dev/null $0 managednodegroup get "$REGION" "$CLUSTER_NAME" "$name" || break

          eksctl "$EKSCTL_COMMON_OPTS" delete nodegroup --region="$REGION" --cluster="$CLUSTER_NAME" --wait "$name" || true
        done

        for stack_name in eksctl-$CLUSTER_NAME-nodegroup-$name; do
          while true; do
            while true; do
              if describe_stacks_output=$(aws --region="$REGION" cloudformation describe-stacks --output=json); then
                break
              fi
              sleep 1
            done

            echo "$describe_stacks_output" | jq -r -e --arg StackName "$stack_name" '.Stacks[] | select(.StackName==$StackName)' || break

            aws --region="$REGION" cloudformation delete-stack --stack-name="$stack_name" || true
          done
        done

        _exit_unless_namespace_eksler

        while true; do
          kubectl delete configmap -n "eksler" "managednodegroup-$name" --ignore-not-found && break
          sleep 1
        done
      ;;
      purge)
        keep=$6
        for managednodegroup in $($0 managednodegroup list "$REGION" "$CLUSTER_NAME"); do
          case "$managednodegroup" in
            "$keep")
              _echoerr "keep $managednodegroup"
            ;;
            $name-*)
              _echoerr "delete $managednodegroup"
              (
                exec $0 managednodegroup delete "$REGION" "$CLUSTER_NAME" "$managednodegroup"
              ) 2>&1 | sed -le "s#^#$managednodegroup: #;" &
            ;;
            *)
              _echoerr "ignore $managednodegroup"
            ;;
          esac
        done

        wait
      ;;
      find)
        for managednodegroup in $($0 managednodegroup list "$REGION" "$CLUSTER_NAME"); do
          case "$managednodegroup" in
            $name-*)
              echo "$managednodegroup"
              exit 0
            ;;
          esac
        done

        exit 1
      ;;
      ensure)
        $0 managednodegroup find "$REGION" "$CLUSTER_NAME" "$name" && exit
        exec $0 managednodegroup create "$REGION" "$CLUSTER_NAME" "$name" "${@:6}"
      ;;
      create)
        revision=$(date +"%Y-%m-%d-%H-%M-%S")
        name_revision="${name}-${revision}"

        label_pairs=""
        for opt in "${@:6}"; do
          case $opt in
            --spot=*)
              spot=${opt#*=}
            ;;
            --vcpus=*)
              vcpus=${opt#*=}
            ;;
            --memory=*)
              memory=${opt#*=}
            ;;
            --label=*)
              label_pairs="$label_pairs ${opt#*=}"
            ;;
            --class=*)
              class=${opt#*=}
            ;;
            --ami=*)
              ami=${opt#*=}
            ;;
            --volume-size=*)
              volume_size=${opt#*=}
            ;;
            --volume-type=*)
              volume_type=${opt#*=}
            ;;
            --volume-iops=*)
              volume_iops=${opt#*=}
            ;;
            --volume-throughput=*)
              volume_throughput=${opt#*=}
            ;;
            --min-size=*)
              min_size=${opt#*=}
            ;;
            --max-size=*)
              max_size=${opt#*=}
              [ "${max_size}" -gt 450 ] && _err "max size ${max_size} greater than 450"
            ;;
            *)
              _err "unknown opt: $opt"
            ;;
          esac
        done

        instances=$(ec2-instance-selector \
          --region="$REGION" \
          --vcpus="$vcpus" \
          --memory="$memory" \
          --hypervisor nitro \
          --cpu-architecture x86_64 \
          --gpus 0 \
          --network-performance-max 25 \
          --root-device-type ebs \
          --deny-list "^vt.|^inf.|d\.|en\.|dn\." \
          --usage-class="$class" \
          --max-results 100
        )

        if [ "$class" = "spot" ]; then
          spot=true
        else
          spot=false
        fi

        if [ "${ami:-}" = "" ]; then
          cluster_version=$($0 cluster version "$REGION" "$CLUSTER_NAME")
          ami=$($0 ami "$REGION" "$cluster_version")
        fi

        volume_size=${volume_size:-4}
        volume_type=${volume_type:-gp3}
        volume_iops=${volume_iops:-3000}
        volume_throughput=${volume_throughput:-125}

        min_size=${min_size:-0}
        max_size=${max_size:-450}

        labels_indented=""
        for label_pair in $label_pairs; do
          key=${label_pair%=*}
          value=${label_pair#*=}

          labels_indented="$labels_indented
      $key: '$value'"
        done

        instances_indented=""
        for instance in $instances; do
          instances_indented="${instances_indented}
      - $instance"
        done

        echo """apiVersion: eksctl.io/v1alpha5
kind: ClusterConfig
metadata:
  name: '$CLUSTER_NAME'
  region: '$REGION'

managedNodeGroups:
  - name: '$name_revision'
    labels: $labels_indented
    volumeType: '$volume_type'
    volumeSize: $volume_size
    volumeIOPS: $volume_iops
    volumeThroughput: $volume_throughput
    minSize: $min_size
    maxSize: $max_size
    spot: $spot
    iam:
      withAddonPolicies:
        autoScaler: true
        imageBuilder: true
        ebs: true
        albIngress: true
    instanceTypes: $instances_indented
    preBootstrapCommands:
      - date > /tmp/eksler.start
      - echo 'changing root password'
      - echo 'root:badpassword' | sudo chpasswd
      - echo 'password changed'
      - sudo yum install -y htop iotop nano screen bind-utils
      - sudo amazon-linux-extras install epel -y
      - date > /tmp/eksler.done
    ami: '$ami'
    overrideBootstrapCommand: |
      #!/bin/bash
      set -euo pipefail
      date > /tmp/eksler.bootstrap.start
      /etc/eks/bootstrap.sh '$CLUSTER_NAME' |& tee /tmp/eksler.bootstrap.output
      echo $? > /tmp/eksler.bootstrap.status
      date > /tmp/eksler.bootstrap.done
""" > "/tmp/eksler.$REGION.$CLUSTER_NAME.nodegroup.$name-$revision.yml"

        cat "/tmp/eksler.$REGION.$CLUSTER_NAME.nodegroup.$name-$revision.yml"

        while true; do
          >/dev/null 2>&1 kubectl get namespace eksler && break
          kubectl create namespace eksler || true
          sleep 1
        done

        _exit_unless_namespace_eksler

        while true; do
          kubectl get configmap -n eksler "managednodegroup-$name_revision" && break
          kubectl create configmap -n eksler "managednodegroup-$name_revision" --from-file=yaml="/tmp/eksler.$REGION.$CLUSTER_NAME.nodegroup.$name-$revision.yml" || true
          sleep 1
        done

        while true; do
          _output "get nodegroup"
          $0 managednodegroup get "$REGION" "$CLUSTER_NAME" "$name_revision" && break

          if ! eksctl "$EKSCTL_COMMON_OPTS" create nodegroup --timeout 6m -f "/tmp/eksler.$REGION.$CLUSTER_NAME.nodegroup.$name-$revision.yml"; then
            _output "failed, delete"
            $0 managednodegroup delete "$REGION" "$CLUSTER_NAME" "$name_revision"
          fi
        done
        _output "purge"
        $0 managednodegroup purge "$REGION" "$CLUSTER_NAME" "$name" "$name_revision"
      ;;
      *)
        handled=no
      ;;
    esac
  ;;
  *)
    handled=no
  ;;
esac

[ "$handled" = "yes" ] && exit